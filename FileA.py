# -*- coding: utf-8 -*-
"""Semantic_Text.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c5gb_lXv3ChCx3YfD4d7gYeVUkx2Pohj
"""

!pip install -r requirement.txt

# Installing sentence transformer library using pip command
!pip install -U sentence-transformers

# installing some important library which will be in use
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

# Storing the model into a model variable for furthur use.
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

data = pd.read_csv('/content/DataNeuron_Text_Similarity.csv')
print("shape"+str(data.shape))
data.head()

data.isnull().sum()

import re
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
nltk.download('wordnet')

from nltk.stem import WordNetLemmatizer

lemm = WordNetLemmatizer()

text1 = []
for i in range(len(data)):
  new = re.sub('[^a-zA-Z]',' ',data.text1[i])
  new = new.lower()
  new = new.split()
  new = [lemm.lemmatize(word) for word in new if word not in set(stopwords.words('english'))]
  new = ' '.join(new)
  text1.append(new)

data.text1[0]

text1[0]

text2 = []
for i in range(len(data)):
  new = re.sub('[^a-zA-Z]',' ',data.text2[i])
  new = new.lower()
  new = new.split()
  new = [lemm.lemmatize(word) for word in new if word not in set(stopwords.words('english'))]
  new = ' '.join(new)
  text2.append(new)

text2[0]

sentence_embeddings_text1 = model.encode(text1)

sentence_embeddings_text2 = model.encode(text2)

# Using cosine Similarity between the vectors and storing similarity score in variable sim
sim = []
for i in range(len(data)):
  cos = cosine_similarity([sentence_embeddings_text1[i]],[sentence_embeddings_text2[i]])
  sim.append(cos)

sim

# Making a dataframe submission
submission = pd.DataFrame()

# Create a new column 'Unique_ID' in the data DataFrame with unique numerical IDs
data['Unique_ID'] = range(len(data))

# Storing Unique_ID in the submission dataframe
submission['Unique_ID'] = data['Unique_ID']
#submission['text1'] = data['text1']

# Storing similarity score in the submission dataframe
submission['Similarity_Score)'] = sim

submission.head()

# Converting dataframe into a CSV file for submission
submission.to_csv('Predicted.csv')

!pip install fuzzywuzzy
from fuzzywuzzy import fuzz

def calculate_similarity(text1, text2):
    # Calculate the similarity score using the fuzz.ratio function
    similarity_score = fuzz.ratio(text1, text2)/100
    return similarity_score

# Prompt the user for two text inputs
text1 = input("Enter the first text: ")
text2 = input("Enter the second text: ")

# Assuming you have already defined a function `calculate_similarity(text1, text2)` in your notebook
similarity_score = calculate_similarity(text1, text2)

# Display the similarity score
print("Similarity score:", similarity_score)

